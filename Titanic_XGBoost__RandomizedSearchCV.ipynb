{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPUGiN/E88Wxts3V6bQb02/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonofaber/Auto-GPT-making/blob/master/Titanic_XGBoost__RandomizedSearchCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwPWNDsaLrDu"
      },
      "outputs": [],
      "source": [
        "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸  => ì¸ì¦ ë° ì•¡ì„¸ìŠ¤ í—ˆ\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WCoAWi-kM7ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° - kaggle ì‚¬ìš©\n",
        "#train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
        "#test = pd.read_csv(\"/kaggle/input/titanic/test.csv\")"
      ],
      "metadata": {
        "id": "kEV7Xo6NL6Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ê²½ë¡œë¥¼ ì‹¤ì œ íŒŒì¼ì´ ìˆëŠ” êµ¬ê¸€ ë“œë¼ì´ë¸Œ ê²½ë¡œë¡œ ìˆ˜ì •\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Titanic/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Titanic/test.csv\")\n",
        "\n",
        "print(train.head())\n",
        "print(test.head())"
      ],
      "metadata": {
        "id": "gdUGI556NSAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()          # ë°ì´í„° íƒ€ì…, ê²°ì¸¡ì¹˜ ë“±\n",
        "train.describe()      # í†µê³„ ìš”ì•½\n",
        "#train['Sex'].value_counts()  # ë²”ì£¼í˜• ë¶„ì„\n",
        "train.isnull().sum()  # ê²°ì¸¡ì¹˜ ê°œìˆ˜"
      ],
      "metadata": {
        "id": "z3udKdZhRK_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ê²°ì¸¡ì¹˜ ì‹œê°í™”\n",
        "import missingno as msno # null data ì‰½ê²Œ ë³´ì—¬ì£¼ëŠ” library\n",
        "msno.matrix(train, figsize=(8, 3))\n",
        "msno.matrix(test, figsize=(8, 3))"
      ],
      "metadata": {
        "id": "aHjpGcquRhK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. ê¸°ì¡´ ì „ì²˜ë¦¬\n",
        "\"\"\"\n",
        "train['Age'] = train['Age'].fillna(train['Age'].median())\n",
        "train['Embarked'] = train['Embarked'].fillna('S')\n",
        "test['Age'] = test['Age'].fillna(test['Age'].median())\n",
        "test['Fare'] = test['Fare'].fillna(test['Fare'].median())\n",
        "\n",
        "train['Sex'] = train['Sex'].map({'male': 0, 'female': 1})\n",
        "test['Sex'] = test['Sex'].map({'male': 0, 'female': 1})\n",
        "train['Embarked'] = train['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
        "test['Embarked'] = test['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nGmWVJHRL823"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3-1 ì „ì²˜ë¦¬ ìˆ˜ì • - ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í™œìš© (K-Nearest Neighbors) ğŸ¤–\n",
        "\"\"\" scikit-learnì˜ KNNImputer ì‚¬ìš©\n",
        " ë‹¤ë¥¸ ëª¨ë“  ìˆ˜ì¹˜ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬, í˜„ì¬ í–‰ê³¼ ê°€ì¥ ìœ ì‚¬í•œ 'K'ê°œì˜ ì´ì›ƒ ë°ì´í„°ë¥¼ ì°¾ì•„ ê·¸ ê°’ë“¤ì˜ í‰ê· ìœ¼ë¡œ ê²°ì¸¡ì¹˜ë¥¼ ì±„ì›€\n",
        " \"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# 2. ìˆ«ìí˜• íŠ¹ì„± ì„ íƒ ë° ìŠ¤ì¼€ì¼ë§\n",
        "impute_features = ['Age', 'Fare', 'Pclass', 'SibSp', 'Parch']\n",
        "\n",
        "# ìŠ¤ì¼€ì¼ë§ ì ìš©\n",
        "scaler = StandardScaler()\n",
        "train_scaled = scaler.fit_transform(train[impute_features])\n",
        "test_scaled = scaler.transform(test[impute_features])\n",
        "\n",
        "# KNN Imputer ì ìš©\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "train[impute_features] = pd.DataFrame(imputer.fit_transform(train_scaled), columns=impute_features)\n",
        "test[impute_features] = pd.DataFrame(imputer.transform(test_scaled), columns=impute_features)\n",
        "\n",
        "# ìŠ¤ì¼€ì¼ë§ ë³µì› (í•„ìš”í•œ ê²½ìš°)\n",
        "train[impute_features] = scaler.inverse_transform(train[impute_features])\n",
        "test[impute_features] = scaler.inverse_transform(test[impute_features])\n",
        "\n",
        "# 3. Embarked ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ìµœë¹ˆê°’ ì‚¬ìš©)\n",
        "train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])\n",
        "test['Embarked'] = test['Embarked'].fillna(train['Embarked'].mode()[0])\n",
        "\n",
        "# 4. ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
        "label_encoder_sex = LabelEncoder()\n",
        "train['Sex'] = label_encoder_sex.fit_transform(train['Sex'])\n",
        "test['Sex'] = label_encoder_sex.transform(test['Sex'])\n",
        "\n",
        "label_encoder_embarked = LabelEncoder()\n",
        "train['Embarked'] = label_encoder_embarked.fit_transform(train['Embarked'])\n",
        "test['Embarked'] = label_encoder_embarked.transform(test['Embarked'])"
      ],
      "metadata": {
        "id": "U3ZnwD6ckuOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ê²°ì¸¡ì¹˜ ì‹œê°í™”\n",
        "import missingno as msno # null data ì‰½ê²Œ ë³´ì—¬ì£¼ëŠ” library\n",
        "msno.matrix(train, figsize=(8, 3))\n",
        "msno.matrix(test, figsize=(8, 3))"
      ],
      "metadata": {
        "id": "P3G1qU4lSPIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. íŠ¹ì„± ì„ íƒ ë° ë°ì´í„° ë¶„ë¦¬\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "X = train[features]\n",
        "y = train['Survived']\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ë¹„êµ) ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)  # ê²½ê³  ë°©ì§€ìš© ì˜µì…˜ í¬í•¨\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# ë¹„êµ) ê²€ì¦ ë°ì´í„°ì…‹ ì˜ˆì¸¡\n",
        "y_pred = xgb_model.predict(X_val)\n",
        "\n",
        "# ë¹„êµ) ì„±ëŠ¥ í‰ê°€\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred))"
      ],
      "metadata": {
        "id": "H-e50EZuMAIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 5. XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„° ë²”ìœ„ ì§€ì •\n",
        "xgb_params = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'max_depth': [4, 6, 8, 10, 20, 30, 40],\n",
        "    'learning_rate': [0.1, 0.2, 0.3],\n",
        "    'min_child_weight': [2, 4, 6, 8, 10],\n",
        "    'subsample': [0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "}\n"
      ],
      "metadata": {
        "id": "_3rsyMoLMGG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. RandomizedSearchCV ê°ì²´ ìƒì„±\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')  # ê²½ê³  ë°©ì§€ë¥¼ ìœ„í•´ ì˜µì…˜ ì¶”ê°€\n",
        "xgb_rs_cv = RandomizedSearchCV(\n",
        "    xgb,\n",
        "    param_distributions=xgb_params,\n",
        "    cv=5,               # 5-Fold êµì°¨ê²€ì¦\n",
        "    n_iter=20,          # 20íšŒ ì¡°í•© ì‹œë„\n",
        "    n_jobs=-1,          # ëª¨ë“  CPU ì‚¬ìš©\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "5eGN6cxMMIcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. íŠœë‹ ìˆ˜í–‰\n",
        "xgb_rs_cv.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Lp5UJAB2MKmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. ìµœì  íŒŒë¼ë¯¸í„° í™•ì¸\n",
        "\n",
        "\"\"\" ë‹¹ì´ˆ íŒŒë¼ë¯¸í„°\n",
        "ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {'subsample': 0.2, 'n_estimators': 200, 'min_child_weight': 2, 'max_depth': 6, 'learning_rate': 0.1}\n",
        "ìµœê³  ì •í™•ë„: 0.8272727272727274\n",
        "\"\"\"\n",
        "\n",
        "print(f\"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {xgb_rs_cv.best_params_}\")\n",
        "print(f\"ìµœê³  ì •í™•ë„: {xgb_rs_cv.best_score_}\")\n"
      ],
      "metadata": {
        "id": "HdB05RVMMN1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. ê²€ì¦ì…‹ ì„±ëŠ¥ í™•ì¸\n",
        "\"\"\" ë‹¹ì´ˆ ê²°ê³¼\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.85      0.87      0.86       105\n",
        "           1       0.81      0.78      0.79        74\n",
        "\n",
        "    accuracy                           0.83       179\n",
        "   macro avg       0.83      0.83      0.83       179\n",
        "weighted avg       0.83      0.83      0.83       179\n",
        "\n",
        "Accuracy: 0.8324022346368715\n",
        "\"\"\"\n",
        "\n",
        "best_model = xgb_rs_cv.best_estimator_\n",
        "y_pred = best_model.predict(X_val)\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n"
      ],
      "metadata": {
        "id": "aSL6gclrMQLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ ë° ìºê¸€ ì œì¶œ csv ìƒì„±\n",
        "X_test = test[features]\n",
        "preds = best_model.predict(X_test)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'PassengerId': test['PassengerId'],\n",
        "    'Survived': preds\n",
        "})\n",
        "\n",
        "#submission.to_csv('submission_xgb.csv', index=False)\n",
        "submission.to_csv('/content/drive/MyDrive/Colab Notebooks/Titanic/submission_xgb.csv', index=False)\n",
        "print(\"íŒŒì¼ì´ '/content/drive/MyDrive/Colab Notebooks/Titanic/' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "id": "DW_F_pxvL2l_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}